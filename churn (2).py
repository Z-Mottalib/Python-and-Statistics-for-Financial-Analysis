# -*- coding: utf-8 -*-
"""churn.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EaRHpAdIHBWQmEchUxEEhYavF9Yct61f

<h3 style='color:blue' align='center'>Customer Churn Prediction Using Artificial Neural Network (ANN)</h3>
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
from matplotlib import pyplot as plt
import numpy as np
# %matplotlib inline

"""**Load the data**"""

df = pd.read_csv("customer_churn.csv")

"""**First of all, drop customerID column as it is of no use**"""

df.drop('customerID',axis='columns',inplace=True)

"""**Quick glance at above makes me realize that TotalCharges should be float but it is an object. Let's check what's going on with  this column**"""

df.TotalCharges.values

"""**Ahh... it is string. Lets convert it to numbers**

**Hmmm... some values seems to be not numbers but blank string. Let's find out such rows**
"""

pd.to_numeric(df.TotalCharges,errors='coerce').isnull()

df[pd.to_numeric(df.TotalCharges,errors='coerce').isnull()]

df.shape

df.iloc[488].TotalCharges

df[df.TotalCharges!=' '].shape

"""**Remove rows with space in TotalCharges**"""

df1 = df[df.TotalCharges!=' ']
df1.shape

df1.TotalCharges = pd.to_numeric(df1.TotalCharges)

df1.TotalCharges.values

"""**Many of the columns are yes, no etc. Let's print unique values in object columns to see data values**"""

def print_unique_col_values(df):
       for column in df:
            if df[column].dtypes=='object':
                print(f'{column}: {df[column].unique()}')

"""**Some of the columns have no internet service or no phone service, that can be replaced with a simple No**"""

df1.replace('No internet service','No',inplace=True)
df1.replace('No phone service','No',inplace=True)

"""**Convert Yes and No to 1 or 0**"""

yes_no_columns = ['Partner','Dependents','PhoneService','MultipleLines','OnlineSecurity','OnlineBackup',
                  'DeviceProtection','TechSupport','StreamingTV','StreamingMovies','PaperlessBilling','Churn']
for col in yes_no_columns:
    df1[col].replace({'Yes': 1,'No': 0},inplace=True)

for col in df1:
    print(f'{col}: {df1[col].unique()}')

df1['gender'].replace({'Female':1,'Male':0},inplace=True)

df1.gender.unique()

"""**One hot encoding for categorical columns**

> Bloc en retrait


"""

df2 = pd.get_dummies(data=df1, columns=['InternetService','Contract','PaymentMethod'])
df2.columns

df2.sample(5)

df2.dtypes

cols_to_scale = ['tenure','MonthlyCharges','TotalCharges']

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
df2[cols_to_scale] = scaler.fit_transform(df2[cols_to_scale])

for col in df2:
    print(f'{col}: {df2[col].unique()}')

"""**Train test split**"""

X = df2.drop('Churn',axis='columns')
y = df2['Churn']

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=5)

X_train[:10]

"""**Build a model (ANN) in tensorflow/keras**"""

import tensorflow as tf
from tensorflow import keras


model = keras.Sequential([
    keras.layers.Dense(26, input_shape=(26,), activation='relu'),
    keras.layers.Dense(15, activation='relu'),
    keras.layers.Dense(1, activation='sigmoid')
])

# opt = keras.optimizers.Adam(learning_rate=0.01)

model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])

history = model.fit(X_train, y_train, epochs=200, validation_data=(X_test, y_test))

model.evaluate(X_test, y_test)

yp = model.predict(X_test)
yp[:5]

y_pred = []
for element in yp:
    if element > 0.5:
        y_pred.append(1)
    else:
        y_pred.append(0)

y_pred[:10]

y_test[:10]

from sklearn.metrics import confusion_matrix , classification_report

print(classification_report(y_test,y_pred))

# Visualisation de la perte
plt.figure(figsize=(12, 6))
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Courbe de Perte')
plt.xlabel('Époques')
plt.ylabel('Perte')
plt.legend()
plt.show()

# Visualisation de la précision
plt.figure(figsize=(12, 6))
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Courbe de Précision')
plt.xlabel('Époques')
plt.ylabel('Précision')
plt.legend()
plt.show()

from sklearn.metrics import confusion_matrix
import seaborn as sns

# Calcul de la matrice de confusion
cm = confusion_matrix(y_test, y_pred)

# Visualisation avec Seaborn
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Prédictions')
plt.ylabel('Vraies valeurs')
plt.title('Matrice de Confusion')
plt.show()

from sklearn.metrics import roc_curve, auc

# Calcul de la courbe ROC
fpr, tpr, thresholds = roc_curve(y_test, yp)
roc_auc = auc(fpr, tpr)

# Visualisation de la courbe ROC
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='darkorange', lw=2, label='Courbe ROC (AUC = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlabel('Taux de Faux Positifs')
plt.ylabel('Taux de Vrais Positifs')
plt.title('Courbe ROC')
plt.legend(loc="lower right")
plt.show()

from sklearn.metrics import precision_recall_curve

# Calcul du diagramme de précision-rappel
precision, recall, _ = precision_recall_curve(y_test, yp)

# Visualisation du diagramme de précision-rappel
plt.figure(figsize=(8, 6))
plt.step(recall, precision, color='b', alpha=0.2, where='post')
plt.fill_between(recall, precision, alpha=0.2, color='b')
plt.xlabel('Rappel')
plt.ylabel('Précision')
plt.title('Diagramme de Précision-Rappel')
plt.show()